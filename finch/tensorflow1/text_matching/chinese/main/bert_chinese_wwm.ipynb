{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert_chinese_wwm.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPx4y+zOyAHhX4aAGH09z7w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"_4hsiHfLy047","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","import os\n","os.chdir('/content/gdrive/My Drive/finch/tensorflow1/text_matching/chinese/main')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"61staQgJy7Ax","colab_type":"code","outputId":"b1bf038e-fda7-4dab-86f9-7be94b6b4a07","executionInfo":{"status":"ok","timestamp":1589854542648,"user_tz":-480,"elapsed":9168,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":360}},"source":["%tensorflow_version 1.x\n","!pip install bert4keras"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","Collecting bert4keras\n","  Downloading https://files.pythonhosted.org/packages/36/37/dfb321f3b50f97512b506fe00ba782bfdaded2cbe97241245a0f4afa54b0/bert4keras-0.7.7.tar.gz\n","Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from bert4keras) (2.3.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->bert4keras) (1.18.4)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->bert4keras) (2.10.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->bert4keras) (3.13)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->bert4keras) (1.0.8)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->bert4keras) (1.1.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->bert4keras) (1.4.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->bert4keras) (1.12.0)\n","Building wheels for collected packages: bert4keras\n","  Building wheel for bert4keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bert4keras: filename=bert4keras-0.7.7-cp36-none-any.whl size=36804 sha256=b90c43df7f212f29d7049f8435ee19ffd93fbace107502f2939835980c98b6b4\n","  Stored in directory: /root/.cache/pip/wheels/73/5f/2b/ee7932b73172503fdb429421c0b433f47a737c0d1c2a85fdd2\n","Successfully built bert4keras\n","Installing collected packages: bert4keras\n","Successfully installed bert4keras-0.7.7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T3KPPoB1zZcz","colab_type":"code","outputId":"f9a67f3d-814c-4e45-9374-b5ced773fa64","executionInfo":{"status":"ok","timestamp":1589854547670,"user_tz":-480,"elapsed":12634,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["import numpy as np\n","import csv\n","\n","from bert4keras.backend import keras, set_gelu, K\n","from bert4keras.tokenizers import Tokenizer\n","from bert4keras.models import build_transformer_model\n","from bert4keras.optimizers import Adam\n","from bert4keras.snippets import sequence_padding, DataGenerator\n","from bert4keras.snippets import open\n","from keras.layers import Dropout, Dense"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"WNM3xIJZy-Ag","colab_type":"code","colab":{}},"source":["def load_data(filename):\n","    D = []\n","    with open(filename, encoding='utf-8') as f:\n","      for i, line in enumerate(csv.reader(f, delimiter=',')):\n","        if i == 0:\n","          continue\n","        text1, text2, label = line\n","        D.append((text1, text2, int(label)))\n","    return D\n","\n","\n","class data_generator(DataGenerator):\n","    def __iter__(self, random=False):\n","        batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n","        for is_end, (text1, text2, label) in self.sample(random):\n","            token_ids, segment_ids = tokenizer.encode(\n","                text1, text2, max_length=maxlen\n","            )\n","            batch_token_ids.append(token_ids)\n","            batch_segment_ids.append(segment_ids)\n","            batch_labels.append([label])\n","            if len(batch_token_ids) == self.batch_size or is_end:\n","                batch_token_ids = sequence_padding(batch_token_ids)\n","                batch_segment_ids = sequence_padding(batch_segment_ids)\n","                batch_labels = sequence_padding(batch_labels)\n","                yield [batch_token_ids, batch_segment_ids], batch_labels\n","                batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n","\n","\n","def evaluate(data):\n","    total, right = 0., 0.\n","    for x_true, y_true in data:\n","        y_pred = model.predict(x_true).argmax(axis=1)\n","        y_true = y_true[:, 0]\n","        total += len(y_true)\n","        right += (y_true == y_pred).sum()\n","    return right / total\n","\n","\n","class Evaluator(keras.callbacks.Callback):\n","    def __init__(self):\n","        self.best_val_acc = 0.\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        val_acc = evaluate(test_generator)\n","        if val_acc > self.best_val_acc:\n","            self.best_val_acc = val_acc\n","            # you can save your model here\n","        print(\n","            'val_acc: {:.4f}, best_val_acc: {:.4f}'.format\n","            (val_acc, self.best_val_acc)\n","        )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"isZ4JExmzEnp","colab_type":"code","outputId":"784454da-d1c3-4f23-f385-e0efdfd8db09","executionInfo":{"status":"ok","timestamp":1589869977838,"user_tz":-480,"elapsed":15437362,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["set_gelu('tanh')\n","maxlen = 64\n","batch_size = 32\n","config_path = '../model/chinese_wwm_L-12_H-768_A-12/bert_config.json'\n","checkpoint_path = '../model/chinese_wwm_L-12_H-768_A-12/bert_model.ckpt'\n","dict_path = '../model/chinese_wwm_L-12_H-768_A-12/vocab.txt'\n","\n","train_data = load_data('../data/train.csv')\n","test_data = load_data('../data/test.csv')\n","\n","tokenizer = Tokenizer(dict_path, do_lower_case=True)\n","\n","train_generator = data_generator(train_data, batch_size)\n","test_generator = data_generator(test_data, batch_size)\n","\n","bert = build_transformer_model(\n","    config_path=config_path,\n","    checkpoint_path=checkpoint_path,\n","    with_pool=True,\n","    return_keras_model=False,\n",")\n","\n","output = Dropout(rate=.1)(bert.model.output)\n","output = Dense(\n","    units=2, activation='softmax', kernel_initializer=bert.initializer\n",")(output)\n","\n","model = keras.models.Model(bert.model.input, output)\n","model.summary()\n","\n","model.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer=Adam(2e-5),\n","    metrics=['accuracy'],\n",")\n","\n","evaluator = Evaluator()\n","model.fit_generator(\n","    train_generator.forfit(),\n","    steps_per_epoch=len(train_generator),\n","    epochs=20,\n","    callbacks=[evaluator]\n",")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","Input-Token (InputLayer)        (None, None)         0                                            \n","__________________________________________________________________________________________________\n","Input-Segment (InputLayer)      (None, None)         0                                            \n","__________________________________________________________________________________________________\n","Embedding-Token (Embedding)     (None, None, 768)    16226304    Input-Token[0][0]                \n","__________________________________________________________________________________________________\n","Embedding-Segment (Embedding)   (None, None, 768)    1536        Input-Segment[0][0]              \n","__________________________________________________________________________________________________\n","Embedding-Token-Segment (Add)   (None, None, 768)    0           Embedding-Token[0][0]            \n","                                                                 Embedding-Segment[0][0]          \n","__________________________________________________________________________________________________\n","Embedding-Position (PositionEmb (None, None, 768)    393216      Embedding-Token-Segment[0][0]    \n","__________________________________________________________________________________________________\n","Embedding-Norm (LayerNormalizat (None, None, 768)    1536        Embedding-Position[0][0]         \n","__________________________________________________________________________________________________\n","Embedding-Dropout (Dropout)     (None, None, 768)    0           Embedding-Norm[0][0]             \n","__________________________________________________________________________________________________\n","Transformer-0-MultiHeadSelfAtte (None, None, 768)    2362368     Embedding-Dropout[0][0]          \n","                                                                 Embedding-Dropout[0][0]          \n","                                                                 Embedding-Dropout[0][0]          \n","__________________________________________________________________________________________________\n","Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Embedding-Dropout[0][0]          \n","                                                                 Transformer-0-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-0-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-0-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-0-FeedForward (Feed (None, None, 768)    4722432     Transformer-0-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-0-FeedForward-Dropo (None, None, 768)    0           Transformer-0-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-0-FeedForward-Add ( (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n","                                                                 Transformer-0-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-0-FeedForward-Norm  (None, None, 768)    1536        Transformer-0-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-1-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-0-FeedForward-Norm[0]\n","                                                                 Transformer-0-FeedForward-Norm[0]\n","                                                                 Transformer-0-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-FeedForward-Norm[0]\n","                                                                 Transformer-1-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-1-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-1-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-1-FeedForward (Feed (None, None, 768)    4722432     Transformer-1-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-1-FeedForward-Dropo (None, None, 768)    0           Transformer-1-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-1-FeedForward-Add ( (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n","                                                                 Transformer-1-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-1-FeedForward-Norm  (None, None, 768)    1536        Transformer-1-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-2-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-1-FeedForward-Norm[0]\n","                                                                 Transformer-1-FeedForward-Norm[0]\n","                                                                 Transformer-1-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-FeedForward-Norm[0]\n","                                                                 Transformer-2-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-2-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-2-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-2-FeedForward (Feed (None, None, 768)    4722432     Transformer-2-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-2-FeedForward-Dropo (None, None, 768)    0           Transformer-2-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-2-FeedForward-Add ( (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n","                                                                 Transformer-2-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-2-FeedForward-Norm  (None, None, 768)    1536        Transformer-2-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-3-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-2-FeedForward-Norm[0]\n","                                                                 Transformer-2-FeedForward-Norm[0]\n","                                                                 Transformer-2-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-FeedForward-Norm[0]\n","                                                                 Transformer-3-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-3-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-3-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-3-FeedForward (Feed (None, None, 768)    4722432     Transformer-3-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-3-FeedForward-Dropo (None, None, 768)    0           Transformer-3-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-3-FeedForward-Add ( (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n","                                                                 Transformer-3-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-3-FeedForward-Norm  (None, None, 768)    1536        Transformer-3-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-4-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-3-FeedForward-Norm[0]\n","                                                                 Transformer-3-FeedForward-Norm[0]\n","                                                                 Transformer-3-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-FeedForward-Norm[0]\n","                                                                 Transformer-4-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-4-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-4-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-4-FeedForward (Feed (None, None, 768)    4722432     Transformer-4-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-4-FeedForward-Dropo (None, None, 768)    0           Transformer-4-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-4-FeedForward-Add ( (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent\n","                                                                 Transformer-4-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-4-FeedForward-Norm  (None, None, 768)    1536        Transformer-4-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-5-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-4-FeedForward-Norm[0]\n","                                                                 Transformer-4-FeedForward-Norm[0]\n","                                                                 Transformer-4-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-FeedForward-Norm[0]\n","                                                                 Transformer-5-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-5-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-5-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-5-FeedForward (Feed (None, None, 768)    4722432     Transformer-5-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-5-FeedForward-Dropo (None, None, 768)    0           Transformer-5-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-5-FeedForward-Add ( (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent\n","                                                                 Transformer-5-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-5-FeedForward-Norm  (None, None, 768)    1536        Transformer-5-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-6-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-5-FeedForward-Norm[0]\n","                                                                 Transformer-5-FeedForward-Norm[0]\n","                                                                 Transformer-5-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-FeedForward-Norm[0]\n","                                                                 Transformer-6-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-6-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-6-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-6-FeedForward (Feed (None, None, 768)    4722432     Transformer-6-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-6-FeedForward-Dropo (None, None, 768)    0           Transformer-6-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-6-FeedForward-Add ( (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent\n","                                                                 Transformer-6-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-6-FeedForward-Norm  (None, None, 768)    1536        Transformer-6-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-7-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-6-FeedForward-Norm[0]\n","                                                                 Transformer-6-FeedForward-Norm[0]\n","                                                                 Transformer-6-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-FeedForward-Norm[0]\n","                                                                 Transformer-7-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-7-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-7-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-7-FeedForward (Feed (None, None, 768)    4722432     Transformer-7-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-7-FeedForward-Dropo (None, None, 768)    0           Transformer-7-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-7-FeedForward-Add ( (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent\n","                                                                 Transformer-7-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-7-FeedForward-Norm  (None, None, 768)    1536        Transformer-7-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-8-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-7-FeedForward-Norm[0]\n","                                                                 Transformer-7-FeedForward-Norm[0]\n","                                                                 Transformer-7-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-FeedForward-Norm[0]\n","                                                                 Transformer-8-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-8-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-8-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-8-FeedForward (Feed (None, None, 768)    4722432     Transformer-8-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-8-FeedForward-Dropo (None, None, 768)    0           Transformer-8-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-8-FeedForward-Add ( (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent\n","                                                                 Transformer-8-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-8-FeedForward-Norm  (None, None, 768)    1536        Transformer-8-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-9-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-8-FeedForward-Norm[0]\n","                                                                 Transformer-8-FeedForward-Norm[0]\n","                                                                 Transformer-8-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-FeedForward-Norm[0]\n","                                                                 Transformer-9-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-9-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-9-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-9-FeedForward (Feed (None, None, 768)    4722432     Transformer-9-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-9-FeedForward-Dropo (None, None, 768)    0           Transformer-9-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-9-FeedForward-Add ( (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent\n","                                                                 Transformer-9-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-9-FeedForward-Norm  (None, None, 768)    1536        Transformer-9-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-10-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-9-FeedForward-Norm[0]\n","                                                                 Transformer-9-FeedForward-Norm[0]\n","                                                                 Transformer-9-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-9-FeedForward-Norm[0]\n","                                                                 Transformer-10-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-10-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-10-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-10-FeedForward (Fee (None, None, 768)    4722432     Transformer-10-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-10-FeedForward-Drop (None, None, 768)    0           Transformer-10-FeedForward[0][0] \n","__________________________________________________________________________________________________\n","Transformer-10-FeedForward-Add  (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten\n","                                                                 Transformer-10-FeedForward-Dropou\n","__________________________________________________________________________________________________\n","Transformer-10-FeedForward-Norm (None, None, 768)    1536        Transformer-10-FeedForward-Add[0]\n","__________________________________________________________________________________________________\n","Transformer-11-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-10-FeedForward-Norm[0\n","                                                                 Transformer-10-FeedForward-Norm[0\n","                                                                 Transformer-10-FeedForward-Norm[0\n","__________________________________________________________________________________________________\n","Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-FeedForward-Norm[0\n","                                                                 Transformer-11-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-11-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-11-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-11-FeedForward (Fee (None, None, 768)    4722432     Transformer-11-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-11-FeedForward-Drop (None, None, 768)    0           Transformer-11-FeedForward[0][0] \n","__________________________________________________________________________________________________\n","Transformer-11-FeedForward-Add  (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten\n","                                                                 Transformer-11-FeedForward-Dropou\n","__________________________________________________________________________________________________\n","Transformer-11-FeedForward-Norm (None, None, 768)    1536        Transformer-11-FeedForward-Add[0]\n","__________________________________________________________________________________________________\n","Pooler (Lambda)                 (None, 768)          0           Transformer-11-FeedForward-Norm[0\n","__________________________________________________________________________________________________\n","Pooler-Dense (Dense)            (None, 768)          590592      Pooler[0][0]                     \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 768)          0           Pooler-Dense[0][0]               \n","__________________________________________________________________________________________________\n","dense_73 (Dense)                (None, 2)            1538        dropout_1[0][0]                  \n","==================================================================================================\n","Total params: 102,269,186\n","Trainable params: 102,269,186\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Epoch 1/20\n","3125/3125 [==============================] - 755s 242ms/step - loss: 0.3337 - accuracy: 0.8556\n","val_acc: 0.8417, best_val_acc: 0.8417\n","Epoch 2/20\n","3125/3125 [==============================] - 747s 239ms/step - loss: 0.1676 - accuracy: 0.9366\n","val_acc: 0.8401, best_val_acc: 0.8417\n","Epoch 3/20\n","3125/3125 [==============================] - 744s 238ms/step - loss: 0.0996 - accuracy: 0.9636\n","val_acc: 0.8306, best_val_acc: 0.8417\n","Epoch 4/20\n","3125/3125 [==============================] - 746s 239ms/step - loss: 0.0684 - accuracy: 0.9758\n","val_acc: 0.8409, best_val_acc: 0.8417\n","Epoch 5/20\n","3125/3125 [==============================] - 745s 238ms/step - loss: 0.0521 - accuracy: 0.9819\n","val_acc: 0.8428, best_val_acc: 0.8428\n","Epoch 6/20\n","3125/3125 [==============================] - 746s 239ms/step - loss: 0.0423 - accuracy: 0.9854\n","val_acc: 0.8386, best_val_acc: 0.8428\n","Epoch 7/20\n","3125/3125 [==============================] - 746s 239ms/step - loss: 0.0368 - accuracy: 0.9874\n","val_acc: 0.8436, best_val_acc: 0.8436\n","Epoch 8/20\n","3125/3125 [==============================] - 746s 239ms/step - loss: 0.0315 - accuracy: 0.9893\n","val_acc: 0.8419, best_val_acc: 0.8436\n","Epoch 9/20\n","3125/3125 [==============================] - 746s 239ms/step - loss: 0.0288 - accuracy: 0.9904\n","val_acc: 0.8357, best_val_acc: 0.8436\n","Epoch 10/20\n","3125/3125 [==============================] - 744s 238ms/step - loss: 0.0269 - accuracy: 0.9908\n","val_acc: 0.8373, best_val_acc: 0.8436\n","Epoch 11/20\n","3125/3125 [==============================] - 747s 239ms/step - loss: 0.0241 - accuracy: 0.9916\n","val_acc: 0.8448, best_val_acc: 0.8448\n","Epoch 12/20\n","3125/3125 [==============================] - 746s 239ms/step - loss: 0.0218 - accuracy: 0.9928\n","val_acc: 0.8414, best_val_acc: 0.8448\n","Epoch 13/20\n","3125/3125 [==============================] - 744s 238ms/step - loss: 0.0212 - accuracy: 0.9932\n","val_acc: 0.8372, best_val_acc: 0.8448\n","Epoch 14/20\n","3125/3125 [==============================] - 744s 238ms/step - loss: 0.0192 - accuracy: 0.9935\n","val_acc: 0.8411, best_val_acc: 0.8448\n","Epoch 15/20\n","3125/3125 [==============================] - 747s 239ms/step - loss: 0.0181 - accuracy: 0.9942\n","val_acc: 0.8399, best_val_acc: 0.8448\n","Epoch 16/20\n","3125/3125 [==============================] - 745s 239ms/step - loss: 0.0178 - accuracy: 0.9941\n","val_acc: 0.8475, best_val_acc: 0.8475\n","Epoch 17/20\n","3125/3125 [==============================] - 744s 238ms/step - loss: 0.0160 - accuracy: 0.9948\n","val_acc: 0.8408, best_val_acc: 0.8475\n","Epoch 18/20\n","3125/3125 [==============================] - 745s 238ms/step - loss: 0.0172 - accuracy: 0.9943\n","val_acc: 0.8454, best_val_acc: 0.8475\n","Epoch 19/20\n","3125/3125 [==============================] - 747s 239ms/step - loss: 0.0152 - accuracy: 0.9952\n","val_acc: 0.8302, best_val_acc: 0.8475\n","Epoch 20/20\n","3125/3125 [==============================] - 744s 238ms/step - loss: 0.0159 - accuracy: 0.9951\n","val_acc: 0.8410, best_val_acc: 0.8475\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7fe2b0daafd0>"]},"metadata":{"tags":[]},"execution_count":5}]}]}