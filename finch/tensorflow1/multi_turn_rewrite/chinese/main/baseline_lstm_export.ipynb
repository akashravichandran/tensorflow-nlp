{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"baseline_lstm_export.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"6LBlfq5fiNOW","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","import os\n","os.chdir('/content/gdrive/My Drive/finch/tensorflow1/multi_turn_rewrite/chinese/main')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jExLuIUKYEOT","colab_type":"code","outputId":"4b6c8079-6790-411b-9a90-a0f4eb863d41","executionInfo":{"status":"ok","timestamp":1587959440752,"user_tz":-480,"elapsed":3506,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["%tensorflow_version 1.x"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RdZa_821Vxmt","colab_type":"code","outputId":"c3bbd83e-25de-48b2-e9e1-c2c23aa2dfc0","executionInfo":{"status":"ok","timestamp":1587959445202,"user_tz":-480,"elapsed":6889,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["import tensorflow as tf\n","import numpy as np\n","\n","print(\"TensorFlow Version\", tf.__version__)\n","print('GPU Enabled:', tf.test.is_gpu_available())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorFlow Version 1.15.2\n","GPU Enabled: False\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c0m1V_2g8pje","colab_type":"code","colab":{}},"source":["def rnn_cell():\n","  def cell_fn():\n","    cell = tf.nn.rnn_cell.LSTMCell(params['hidden_units'],\n","                                   initializer=tf.orthogonal_initializer())\n","    return cell\n","  if params['dec_layers'] > 1:\n","    cells = []\n","    for i in range(params['dec_layers']):\n","      if i == params['dec_layers'] - 1:\n","        cells.append(cell_fn())\n","      else:\n","        cells.append(tf.nn.rnn_cell.ResidualWrapper(cell_fn(), residual_fn=lambda i,o: tf.concat((i,o), -1)))\n","    return tf.nn.rnn_cell.MultiRNNCell(cells)\n","  else:\n","    return cell_fn()\n","\n","  \n","def dec_cell(enc_out, enc_seq_len):\n","  query, history = enc_out\n","  query_len, history_len = enc_seq_len\n","\n","  attn1 = tf.contrib.seq2seq.BahdanauAttention(\n","    num_units = params['hidden_units'],\n","    memory = query,\n","    memory_sequence_length = query_len)\n","  \n","  attn2 = tf.contrib.seq2seq.BahdanauAttention(\n","    num_units = params['hidden_units'],\n","    memory = history,\n","    memory_sequence_length = history_len)\n","  \n","  return tf.contrib.seq2seq.AttentionWrapper(\n","    cell = rnn_cell(),\n","    attention_mechanism = [attn1, attn2],\n","    attention_layer_size = [params['hidden_units']//2, params['hidden_units']//2])\n","    \n","\n","class TiedDense(tf.layers.Layer):\n","  def __init__(self, tied_embed, out_dim):\n","    super().__init__()\n","    self.tied_embed = tied_embed\n","    self.out_dim = out_dim\n","  \n","  def build(self, input_shape):\n","    self.bias = self.add_weight(name='bias',\n","                                shape=[self.out_dim],\n","                                trainable=True)\n","    super().build(input_shape)\n","  \n","  def call(self, inputs):\n","    x = tf.matmul(inputs, self.tied_embed, transpose_b=True)\n","    x = tf.nn.bias_add(x, self.bias)\n","    return x\n","  \n","  def compute_output_shape(self, input_shape):\n","    return input_shape[:-1].concatenate(self.out_dim)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"61sf9BGk9_yi","colab_type":"code","colab":{}},"source":["def bilstm_encode(encoder, x, mask):\n","  enc_out, state_fw_h, state_fw_c, state_bw_h, state_bw_c = encoder(x, mask=mask)\n","  enc_state = tf.concat((state_fw_h, state_bw_h), axis=-1)\n","  return enc_out, enc_state\n","\n","\n","def greedy_search(embedding, enc_out, enc_state, words_len, batch_sz, params, output_proj):\n","  cell = dec_cell(enc_out, words_len)\n","  init_state = cell.zero_state(batch_sz, tf.float32).clone(\n","    cell_state=enc_state)\n","  \n","  helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n","    embedding = embedding,\n","    start_tokens = tf.tile(tf.constant([1], tf.int32), [batch_sz]),\n","    end_token = 2,)\n","  decoder = tf.contrib.seq2seq.BasicDecoder(\n","    cell = cell,\n","    helper = helper,\n","    initial_state = init_state,\n","    output_layer = output_proj)\n","  decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\n","    decoder = decoder,\n","    maximum_iterations = params['max_len'])\n","  \n","  return decoder_output.sample_id\n","\n","\n","def beam_search(embedding, enc_out, enc_state, words_len, batch_sz, params, output_proj):\n","  enc_out_t = [tf.contrib.seq2seq.tile_batch(e, params['beam_width']) for e in enc_out]\n","  enc_state_t = tf.contrib.seq2seq.tile_batch(enc_state, params['beam_width'])\n","  enc_seq_len_t = []\n","  for l in words_len:\n","    if l is not None:\n","      enc_seq_len_t.append(tf.contrib.seq2seq.tile_batch(l, params['beam_width']))\n","    else:\n","      enc_seq_len_t.append(l)\n","  \n","  cell = dec_cell(enc_out_t, enc_seq_len_t)\n","  \n","  init_state = cell.zero_state(batch_sz*params['beam_width'], tf.float32).clone(\n","    cell_state=enc_state_t)\n","  \n","  decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n","    cell = cell,\n","    embedding = embedding,\n","    start_tokens = tf.tile(tf.constant([1], tf.int32), [batch_sz]),\n","    end_token = 2,\n","    initial_state = init_state,\n","    beam_width = params['beam_width'],\n","    output_layer = output_proj,\n","    length_penalty_weight = params['length_penalty'],\n","    coverage_penalty_weight = params['coverage_penalty'],)\n","  decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\n","    decoder = decoder,\n","    maximum_iterations = params['max_len'],)\n","  \n","  return decoder_output.predicted_ids[:, :, 0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jU4fiGsdayFF","colab_type":"code","colab":{}},"source":["def dynamic_memory_update(query, history):\n","  proj_1 = tf.layers.Dense(params['hidden_units'], params['activation'], name='attn_proj_1')\n","  proj_2 = tf.layers.Dense(1, use_bias=False, name='attn_proj_2')\n","  memory_proj = tf.layers.Dense(params['hidden_units'], params['activation'], name='memory_proj')\n","\n","  memory = query\n","  for i in range(params['num_hops']):\n","    episode = gen_episode(memory,\n","                          query,\n","                          history,\n","                          proj_1,\n","                          proj_2,)\n","    memory = memory_proj(tf.concat([memory, episode, query], 1))\n","\n","  lstm_memory = tf.nn.rnn_cell.LSTMStateTuple(c=memory, h=memory)\n","  if params['dec_layers'] > 1:\n","    lstm_memory = tuple(params['dec_layers'] * [lstm_memory])\n","  \n","  return lstm_memory\n","\n","\n","def gen_episode(memory, q_vec, fact_vecs, proj_1, proj_2):\n","  def gen_attn(fact_vec):\n","    features = [fact_vec * q_vec,\n","                fact_vec * memory,\n","                tf.abs(fact_vec - q_vec),\n","                tf.abs(fact_vec - memory)]\n","    feature_vec = tf.concat(features, 1)\n","    attention = proj_1(feature_vec)\n","    attention = proj_2(attention)\n","    return tf.squeeze(attention, 1)\n","  \n","  attns = tf.map_fn(gen_attn, tf.transpose(fact_vecs, [1,0,2]))\n","  attns = tf.transpose(attns)                                     \n","  attns = params['gating_fn'](attns)                              \n","  attns = tf.expand_dims(attns, -1)                               \n","  episode = tf.matmul(fact_vecs, attns, transpose_a=True)\n","  episode = tf.squeeze(episode, -1)\n","\n","  return episode"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zZFQF5599jWZ","colab_type":"code","colab":{}},"source":["def forward(features, labels, mode):\n","  history = features['history']\n","  query = features['query']\n","\n","  is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n","  batch_sz = tf.shape(query)[0]\n","\n","  query_valid_len = tf.count_nonzero(query, 1, dtype=tf.int32)\n","  query_mask = tf.sign(query)\n","\n","  num_history = tf.shape(history)[1]\n","  history_len = tf.shape(history)[2]\n","  history = tf.reshape(history, (num_history*batch_sz, history_len))\n","  history_mask = tf.sign(history)\n","  \n","  \n","  with tf.variable_scope('Embedding'):\n","    embedding = tf.Variable(np.load('../vocab/char.npy'),\n","                            dtype=tf.float32,\n","                            name='fasttext_vectors')\n","    def embed_fn(x):\n","      x = tf.nn.embedding_lookup(embedding, x)\n","      return x\n","    query = embed_fn(query)\n","    history = embed_fn(history)\n","  \n","  \n","  with tf.variable_scope('Encoder'):\n","    encoder = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(\n","      params['hidden_units'], return_state=True, return_sequences=True, zero_output_for_mask=True))\n","\n","    query_out, query_state = bilstm_encode(encoder, query, query_mask)\n","    history_out, history_state = bilstm_encode(encoder, history, history_mask)\n","\n","    feat_proj_1 = tf.layers.Dense(params['hidden_units'], params['activation'], name='feat_proj_1')\n","    feat_proj_2 = tf.layers.Dense(params['hidden_units'], params['activation'], name='feat_proj_2')\n","\n","    def feat_engine(out, state):\n","      x = tf.concat([state, tf.reduce_max(out, 1)], -1)\n","      x = feat_proj_1(x)\n","      x = feat_proj_2(x)\n","      return x\n","    \n","    query_feat = feat_engine(query_out, query_state)\n","    history_feat = tf.reshape(feat_engine(history_out, history_state), (batch_sz, num_history, params['hidden_units']))\n","\n","\n","  with tf.variable_scope('Dynamic_Memory'): \n","    dynamic_memory = dynamic_memory_update(query_feat, history_feat)\n","    query_memory = query_out\n","    history_memory = tf.reshape(history_out, (batch_sz, num_history*history_len, 2*params['hidden_units']))\n","    static_memory = [query_memory, history_memory]\n","    memory_len = [query_valid_len, None]\n","\n","\n","  with tf.variable_scope('Decoder'):\n","    output_proj = TiedDense(embedding, len(params['char2idx'])+1)\n","    return beam_search(embedding, static_memory, dynamic_memory, memory_len, batch_sz, params, output_proj)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cVBUz0cBsARO","colab_type":"code","colab":{}},"source":["def model_fn(features, labels, mode, params):\n","    logits_or_ids = forward(features, labels, mode)\n","    if mode == tf.estimator.ModeKeys.PREDICT:\n","        return tf.estimator.EstimatorSpec(mode, predictions=logits_or_ids)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0mX1qxxQkpZK","colab_type":"code","colab":{}},"source":["def get_vocab(f_path):\n","  word2idx = {}\n","  with open(f_path) as f:\n","    for i, line in enumerate(f):\n","      line = line.rstrip('\\n')\n","      word2idx[line] = i\n","  return word2idx"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fdd1mf4hY6tU","colab_type":"code","colab":{}},"source":["params = {\n","    'model_dir': '../model/baseline_lstm',\n","    'export_dir': '../model/baseline_lstm_beam_export',\n","    'vocab_path': '../vocab/char.txt',\n","    'max_len': 30,\n","    'activation': tf.nn.relu,\n","    'hidden_units': 300,\n","    'dec_layers': 1,\n","    'num_hops': 3,\n","    'gating_fn': tf.sigmoid,\n","    'beam_width': 10,\n","    'length_penalty': .0,\n","    'coverage_penalty': .0,\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CMsIhTdSY7n8","colab_type":"code","colab":{}},"source":["params['char2idx'] = get_vocab(params['vocab_path'])\n","params['idx2char'] = {idx: char for char, idx in params['char2idx'].items()}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tnSW-dRrpJDW","colab_type":"code","colab":{}},"source":["def serving_input_receiver_fn():\n","    query = tf.placeholder(tf.int32, [None, None], 'query')\n","    history = tf.placeholder(tf.int32, [None, None, None], 'history')\n","    \n","    features = {'query': query, 'history': history}\n","    receiver_tensors = features\n","    \n","    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AtmpnldTj3A_","colab_type":"code","outputId":"711162e0-4c72-44c6-f381-9b026c8bf8c3","executionInfo":{"status":"ok","timestamp":1587959565822,"user_tz":-480,"elapsed":4453,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":532}},"source":["estimator = tf.estimator.Estimator(model_fn, params['model_dir'])\n","estimator.export_saved_model(params['export_dir'], serving_input_receiver_fn)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using default config.\n","INFO:tensorflow:Using config: {'_model_dir': '../model/baseline_lstm', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f24fad50cc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x7f250137b048>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Calling model_fn.\n","WARNING:tensorflow:Entity <bound method TiedDense.call of <__main__.TiedDense object at 0x7f24faa2ef98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","WARNING: Entity <bound method TiedDense.call of <__main__.TiedDense object at 0x7f24faa2ef98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/seq2seq/python/ops/beam_search_decoder.py:971: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n","INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n","INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n","INFO:tensorflow:Signatures INCLUDED in export for Train: None\n","INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n","INFO:tensorflow:Restoring parameters from ../model/baseline_lstm/model.ckpt-35610\n","INFO:tensorflow:Assets added to graph.\n","INFO:tensorflow:No assets to write.\n","INFO:tensorflow:SavedModel written to: ../model/baseline_lstm_beam_export/temp-b'1587959561'/saved_model.pb\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["b'../model/baseline_lstm_beam_export/1587959561'"]},"metadata":{"tags":[]},"execution_count":18}]}]}